在某些情况下，您可能想要实现一个自定义解析器来将模型输出结构化为自定义格式。

实现自定义解析器有两种方式：
1. 使用LCEL中的`RunnableLambda`或`RunnableGenerator` - 我们强烈推荐这种方式用于大多数用例。
2. 通过继承输出解析的基础类 - 这是实现解析器的困难方式。

这两种方法之间的区别主要是表面的，主要在于触发的回调不同（例如，`on_chain_start`与`on_parser_start`），以及在像LangSmith这样的追踪平台上，可运行的lambda与解析器可能被以不同的方式可视化。

## 1、可运行的Lambda和生成器
推荐的方式是使用**可运行的Lambda**和**可运行的生成器**！

在这里，我们将创建一个简单的解析器，用于反转模型输出的大小写。

例如，如果模型输出：“Meow”，解析器将产生“mEOW”。

```python
from langchain_openai import ChatOpenAI

model = ChatOpenAI(model="gpt-3.5-turbo")

from langchain_core.messages import AIMessage, AIMessageChunk


def parse(ai_message: AIMessage) -> str:
    """解析AI消息。"""
    return ai_message.content.swapcase()


chain = model | parse

print(chain.invoke("hello"))
```

LCEL在通过`|`语法组合时，会自动将函数`parse`升级为`RunnableLambda(parse)`。

如果您不喜欢这样，您可以手动导入`RunnableLambda`，然后运行`parse = RunnableLambda(parse)`。

流式传输工作吗？

```python
for chunk in chain.stream("tell me about yourself in one sentence"):
    print(chunk, end="|", flush=True)
```

```
i AM A DEDICATED AND HARDWORKING INDIVIDUAL WHO IS PASSIONATE ABOUT LEARNING AND GROWING IN ALL ASPECTS OF LIFE.|
```

不，它不会，因为解析器在解析输出之前会聚合输入。

如果我们想实现一个流式解析器，我们可以让解析器接受输入的可迭代对象，并在结果可用时产生它们。

```python
from langchain_core.runnables import RunnableGenerator

def streaming_parse(chunks: Iterable[AIMessageChunk]) -> Iterable[str]:
    for chunk in chunks:
        yield chunk.content.swapcase()

streaming_parse = RunnableGenerator(streaming_parse)
```

请将流式解析器包装在`RunnableGenerator`中，因为我们可能会停止自动使用`|`语法升级它。

```python
chain = model | streaming_parse

chain.invoke("hello")
```

让我们确认流式传输是否工作！

```python
for chunk in chain.stream("tell me about yourself in one sentence"):
    print(chunk, end="|", flush=True)
```

```text
|i| AM| A| DEDICATED| AND| HARD|WORKING| INDIVIDUAL| WHO| IS| PASSIONATE| ABOUT| LEARNING| AND| GROWING| IN| ALL| ASPECTS| OF| LIFE|.||
```

## 2、继承自解析基础类
实现解析器的另一种方法是通过继承`BaseOutputParser`、`BaseGenerationOutputParser`或根据您的需求继承其他基础解析器。

一般来说，我们**不**推荐这种方式用于大多数用例，因为它会导致编写更多的代码而没有显著的好处。

最简单的输出解析器扩展了`BaseOutputParser`类，并必须实现以下方法：
- `parse`：接受模型的字符串输出并解析它
- (可选) `_type`：标识解析器的名称。

当聊天模型或LLM的输出格式不正确时，可以抛出`OutputParserException`来表示由于输入错误而导致解析失败。使用此异常允许使用解析器的代码以一致的方式处理异常。

:::{.callout-tip} 解析器是可运行的！ 🏃

因为`BaseOutputParser`实现了`Runnable`接口，您以这种方式创建的任何自定义解析器都将成为有效的LangChain可运行对象，并将从自动异步支持、批量接口、日志记录支持等中受益。

### （1）简单解析器
这是一个可以解析**布尔值**的字符串表示（例如，“YES”或“NO”）并将其转换为相应的布尔类型的简单解析器。

```python
from langchain_core.exceptions import OutputParserException
from langchain_core.output_parsers import BaseOutputParser

# [bool] 描述了泛型的一个参数化。
# 它基本上指示了解析的返回类型是什么
# 在这种情况下，返回类型是True或False

class BooleanOutputParser(BaseOutputParser[bool]):
    """自定义布尔解析器。"""
    true_val: str = "YES"
    false_val: str = "NO"

    def parse(self, text: str) -> bool:
        cleaned_text = text.strip().upper()
        if cleaned_text not in (self.true_val.upper(), self.false_val.upper()):
            raise OutputParserException(
                f"BooleanOutputParser expected output value to either be "
                f"\"{self.true_val} or {self.false_val} (case-insensitive). "
                f"Received {cleaned_text}."
            )
        return cleaned_text == self.true_val.upper()

    @property
    def _type(self) -> str:
        return "boolean_output_parser"
```

```python
parser = BooleanOutputParser()
parser.invoke("YES")
```

尝试触发一个异常：

```python
try:
    parser.invoke("MEOW")
except Exception as e:
    print(f"Triggered an exception of type: {type(e)}")
```

```
触发了一个类型为 <class 'langchain_core.exceptions.OutputParserException'> 的异常
```

让我们测试改变参数化：

```python
parser = BooleanOutputParser(true_val="OKAY")
parser.invoke("OKAY")
```

让我们确认其他LCEL方法是否存在：

```python
parser.batch(["OKAY", "NO"])
```

```python
await parser.abatch(["OKAY", "NO"])
```

```python
from langchain_anthropic.chat_models import ChatAnthropic
anthropic = ChatAnthropic(model_name="claude-2.1")
anthropic.invoke("say OKAY or NO")
```

```python
AIMessage(content='OKAY')
```

让我们测试我们的解析器是否工作！

```python
chain = anthropic | parser
chain.invoke("say OKAY or NO")
```

!>解析器将与LLM的输出（一个字符串）或聊天模型的输出（一个`AIMessage`）一起工作！

### （2）解析原始模型输出
有时模型输出上有一些重要的元数据，除了原始文本之外。一个例子是工具调用，其中打算传递给被调用函数的参数在一个单独的属性中返回。如果您需要这种更细粒度的控制，您可以改而继承`BaseGenerationOutputParser`类。

这个类需要一个单一的方法`parse_result`。这个方法接受原始模型输出（例如，`Generation`或`ChatGeneration`的列表）并返回解析后的输出。

支持`Generation`和`ChatGeneration`允许解析器与常规LLM以及聊天模型一起工作。

```python
from typing import List

from langchain_core.exceptions import OutputParserException
from langchain_core.messages import AIMessage
from langchain_core.output_parsers import BaseGenerationOutputParser
from langchain_core.outputs import ChatGeneration, Generation


class StrInvertCase(BaseGenerationOutputParser[str]):
    """An example parser that inverts the case of the characters in the message.

    This is an example parse shown just for demonstration purposes and to keep
    the example as simple as possible.
    """

    def parse_result(self, result: List[Generation], *, partial: bool = False) -> str:
        """Parse a list of model Generations into a specific format.

        Args:
            result: A list of Generations to be parsed. The Generations are assumed
                to be different candidate outputs for a single model input.
                Many parsers assume that only a single generation is passed it in.
                We will assert for that
            partial: Whether to allow partial results. This is used for parsers
                     that support streaming
        """
        if len(result) != 1:
            raise NotImplementedError(
                "This output parser can only be used with a single generation."
            )
        generation = result[0]
        if not isinstance(generation, ChatGeneration):
            # Say that this one only works with chat generations
            raise OutputParserException(
                "This output parser can only be used with a chat generation."
            )
        return generation.message.content.swapcase()


chain = anthropic | StrInvertCase()
```

让我们测试新的解析器！它应该反转模型的输出。

```python
chain.invoke("Tell me a short sentence about yourself")
```