åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œæ‚¨å¯èƒ½æƒ³è¦å®ç°ä¸€ä¸ªè‡ªå®šä¹‰è§£æå™¨æ¥å°†æ¨¡å‹è¾“å‡ºç»“æ„åŒ–ä¸ºè‡ªå®šä¹‰æ ¼å¼ã€‚

å®ç°è‡ªå®šä¹‰è§£æå™¨æœ‰ä¸¤ç§æ–¹å¼ï¼š
1. ä½¿ç”¨LCELä¸­çš„`RunnableLambda`æˆ–`RunnableGenerator` - æˆ‘ä»¬å¼ºçƒˆæ¨èè¿™ç§æ–¹å¼ç”¨äºå¤§å¤šæ•°ç”¨ä¾‹ã€‚
2. é€šè¿‡ç»§æ‰¿è¾“å‡ºè§£æçš„åŸºç¡€ç±» - è¿™æ˜¯å®ç°è§£æå™¨çš„å›°éš¾æ–¹å¼ã€‚

è¿™ä¸¤ç§æ–¹æ³•ä¹‹é—´çš„åŒºåˆ«ä¸»è¦æ˜¯è¡¨é¢çš„ï¼Œä¸»è¦åœ¨äºè§¦å‘çš„å›è°ƒä¸åŒï¼ˆä¾‹å¦‚ï¼Œ`on_chain_start`ä¸`on_parser_start`ï¼‰ï¼Œä»¥åŠåœ¨åƒLangSmithè¿™æ ·çš„è¿½è¸ªå¹³å°ä¸Šï¼Œå¯è¿è¡Œçš„lambdaä¸è§£æå™¨å¯èƒ½è¢«ä»¥ä¸åŒçš„æ–¹å¼å¯è§†åŒ–ã€‚

## 1ã€å¯è¿è¡Œçš„Lambdaå’Œç”Ÿæˆå™¨
æ¨èçš„æ–¹å¼æ˜¯ä½¿ç”¨**å¯è¿è¡Œçš„Lambda**å’Œ**å¯è¿è¡Œçš„ç”Ÿæˆå™¨**ï¼

åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªç®€å•çš„è§£æå™¨ï¼Œç”¨äºåè½¬æ¨¡å‹è¾“å‡ºçš„å¤§å°å†™ã€‚

ä¾‹å¦‚ï¼Œå¦‚æœæ¨¡å‹è¾“å‡ºï¼šâ€œMeowâ€ï¼Œè§£æå™¨å°†äº§ç”Ÿâ€œmEOWâ€ã€‚

```python
from langchain_openai import ChatOpenAI

model = ChatOpenAI(model="gpt-3.5-turbo")

from langchain_core.messages import AIMessage, AIMessageChunk


def parse(ai_message: AIMessage) -> str:
    """è§£æAIæ¶ˆæ¯ã€‚"""
    return ai_message.content.swapcase()


chain = model | parse

print(chain.invoke("hello"))
```

LCELåœ¨é€šè¿‡`|`è¯­æ³•ç»„åˆæ—¶ï¼Œä¼šè‡ªåŠ¨å°†å‡½æ•°`parse`å‡çº§ä¸º`RunnableLambda(parse)`ã€‚

å¦‚æœæ‚¨ä¸å–œæ¬¢è¿™æ ·ï¼Œæ‚¨å¯ä»¥æ‰‹åŠ¨å¯¼å…¥`RunnableLambda`ï¼Œç„¶åè¿è¡Œ`parse = RunnableLambda(parse)`ã€‚

æµå¼ä¼ è¾“å·¥ä½œå—ï¼Ÿ

```python
for chunk in chain.stream("tell me about yourself in one sentence"):
    print(chunk, end="|", flush=True)
```

```
i AM A DEDICATED AND HARDWORKING INDIVIDUAL WHO IS PASSIONATE ABOUT LEARNING AND GROWING IN ALL ASPECTS OF LIFE.|
```

ä¸ï¼Œå®ƒä¸ä¼šï¼Œå› ä¸ºè§£æå™¨åœ¨è§£æè¾“å‡ºä¹‹å‰ä¼šèšåˆè¾“å…¥ã€‚

å¦‚æœæˆ‘ä»¬æƒ³å®ç°ä¸€ä¸ªæµå¼è§£æå™¨ï¼Œæˆ‘ä»¬å¯ä»¥è®©è§£æå™¨æ¥å—è¾“å…¥çš„å¯è¿­ä»£å¯¹è±¡ï¼Œå¹¶åœ¨ç»“æœå¯ç”¨æ—¶äº§ç”Ÿå®ƒä»¬ã€‚

```python
from langchain_core.runnables import RunnableGenerator

def streaming_parse(chunks: Iterable[AIMessageChunk]) -> Iterable[str]:
    for chunk in chunks:
        yield chunk.content.swapcase()

streaming_parse = RunnableGenerator(streaming_parse)
```

è¯·å°†æµå¼è§£æå™¨åŒ…è£…åœ¨`RunnableGenerator`ä¸­ï¼Œå› ä¸ºæˆ‘ä»¬å¯èƒ½ä¼šåœæ­¢è‡ªåŠ¨ä½¿ç”¨`|`è¯­æ³•å‡çº§å®ƒã€‚

```python
chain = model | streaming_parse

chain.invoke("hello")
```

è®©æˆ‘ä»¬ç¡®è®¤æµå¼ä¼ è¾“æ˜¯å¦å·¥ä½œï¼

```python
for chunk in chain.stream("tell me about yourself in one sentence"):
    print(chunk, end="|", flush=True)
```

```text
|i| AM| A| DEDICATED| AND| HARD|WORKING| INDIVIDUAL| WHO| IS| PASSIONATE| ABOUT| LEARNING| AND| GROWING| IN| ALL| ASPECTS| OF| LIFE|.||
```

## 2ã€ç»§æ‰¿è‡ªè§£æåŸºç¡€ç±»
å®ç°è§£æå™¨çš„å¦ä¸€ç§æ–¹æ³•æ˜¯é€šè¿‡ç»§æ‰¿`BaseOutputParser`ã€`BaseGenerationOutputParser`æˆ–æ ¹æ®æ‚¨çš„éœ€æ±‚ç»§æ‰¿å…¶ä»–åŸºç¡€è§£æå™¨ã€‚

ä¸€èˆ¬æ¥è¯´ï¼Œæˆ‘ä»¬**ä¸**æ¨èè¿™ç§æ–¹å¼ç”¨äºå¤§å¤šæ•°ç”¨ä¾‹ï¼Œå› ä¸ºå®ƒä¼šå¯¼è‡´ç¼–å†™æ›´å¤šçš„ä»£ç è€Œæ²¡æœ‰æ˜¾è‘—çš„å¥½å¤„ã€‚

æœ€ç®€å•çš„è¾“å‡ºè§£æå™¨æ‰©å±•äº†`BaseOutputParser`ç±»ï¼Œå¹¶å¿…é¡»å®ç°ä»¥ä¸‹æ–¹æ³•ï¼š
- `parse`ï¼šæ¥å—æ¨¡å‹çš„å­—ç¬¦ä¸²è¾“å‡ºå¹¶è§£æå®ƒ
- (å¯é€‰) `_type`ï¼šæ ‡è¯†è§£æå™¨çš„åç§°ã€‚

å½“èŠå¤©æ¨¡å‹æˆ–LLMçš„è¾“å‡ºæ ¼å¼ä¸æ­£ç¡®æ—¶ï¼Œå¯ä»¥æŠ›å‡º`OutputParserException`æ¥è¡¨ç¤ºç”±äºè¾“å…¥é”™è¯¯è€Œå¯¼è‡´è§£æå¤±è´¥ã€‚ä½¿ç”¨æ­¤å¼‚å¸¸å…è®¸ä½¿ç”¨è§£æå™¨çš„ä»£ç ä»¥ä¸€è‡´çš„æ–¹å¼å¤„ç†å¼‚å¸¸ã€‚

:::{.callout-tip} è§£æå™¨æ˜¯å¯è¿è¡Œçš„ï¼ ğŸƒ

å› ä¸º`BaseOutputParser`å®ç°äº†`Runnable`æ¥å£ï¼Œæ‚¨ä»¥è¿™ç§æ–¹å¼åˆ›å»ºçš„ä»»ä½•è‡ªå®šä¹‰è§£æå™¨éƒ½å°†æˆä¸ºæœ‰æ•ˆçš„LangChainå¯è¿è¡Œå¯¹è±¡ï¼Œå¹¶å°†ä»è‡ªåŠ¨å¼‚æ­¥æ”¯æŒã€æ‰¹é‡æ¥å£ã€æ—¥å¿—è®°å½•æ”¯æŒç­‰ä¸­å—ç›Šã€‚

### ï¼ˆ1ï¼‰ç®€å•è§£æå™¨
è¿™æ˜¯ä¸€ä¸ªå¯ä»¥è§£æ**å¸ƒå°”å€¼**çš„å­—ç¬¦ä¸²è¡¨ç¤ºï¼ˆä¾‹å¦‚ï¼Œâ€œYESâ€æˆ–â€œNOâ€ï¼‰å¹¶å°†å…¶è½¬æ¢ä¸ºç›¸åº”çš„å¸ƒå°”ç±»å‹çš„ç®€å•è§£æå™¨ã€‚

```python
from langchain_core.exceptions import OutputParserException
from langchain_core.output_parsers import BaseOutputParser

# [bool] æè¿°äº†æ³›å‹çš„ä¸€ä¸ªå‚æ•°åŒ–ã€‚
# å®ƒåŸºæœ¬ä¸ŠæŒ‡ç¤ºäº†è§£æçš„è¿”å›ç±»å‹æ˜¯ä»€ä¹ˆ
# åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè¿”å›ç±»å‹æ˜¯Trueæˆ–False

class BooleanOutputParser(BaseOutputParser[bool]):
    """è‡ªå®šä¹‰å¸ƒå°”è§£æå™¨ã€‚"""
    true_val: str = "YES"
    false_val: str = "NO"

    def parse(self, text: str) -> bool:
        cleaned_text = text.strip().upper()
        if cleaned_text not in (self.true_val.upper(), self.false_val.upper()):
            raise OutputParserException(
                f"BooleanOutputParser expected output value to either be "
                f"\"{self.true_val} or {self.false_val} (case-insensitive). "
                f"Received {cleaned_text}."
            )
        return cleaned_text == self.true_val.upper()

    @property
    def _type(self) -> str:
        return "boolean_output_parser"
```

```python
parser = BooleanOutputParser()
parser.invoke("YES")
```

å°è¯•è§¦å‘ä¸€ä¸ªå¼‚å¸¸ï¼š

```python
try:
    parser.invoke("MEOW")
except Exception as e:
    print(f"Triggered an exception of type: {type(e)}")
```

```
è§¦å‘äº†ä¸€ä¸ªç±»å‹ä¸º <class 'langchain_core.exceptions.OutputParserException'> çš„å¼‚å¸¸
```

è®©æˆ‘ä»¬æµ‹è¯•æ”¹å˜å‚æ•°åŒ–ï¼š

```python
parser = BooleanOutputParser(true_val="OKAY")
parser.invoke("OKAY")
```

è®©æˆ‘ä»¬ç¡®è®¤å…¶ä»–LCELæ–¹æ³•æ˜¯å¦å­˜åœ¨ï¼š

```python
parser.batch(["OKAY", "NO"])
```

```python
await parser.abatch(["OKAY", "NO"])
```

```python
from langchain_anthropic.chat_models import ChatAnthropic
anthropic = ChatAnthropic(model_name="claude-2.1")
anthropic.invoke("say OKAY or NO")
```

```python
AIMessage(content='OKAY')
```

è®©æˆ‘ä»¬æµ‹è¯•æˆ‘ä»¬çš„è§£æå™¨æ˜¯å¦å·¥ä½œï¼

```python
chain = anthropic | parser
chain.invoke("say OKAY or NO")
```

!>è§£æå™¨å°†ä¸LLMçš„è¾“å‡ºï¼ˆä¸€ä¸ªå­—ç¬¦ä¸²ï¼‰æˆ–èŠå¤©æ¨¡å‹çš„è¾“å‡ºï¼ˆä¸€ä¸ª`AIMessage`ï¼‰ä¸€èµ·å·¥ä½œï¼

### ï¼ˆ2ï¼‰è§£æåŸå§‹æ¨¡å‹è¾“å‡º
æœ‰æ—¶æ¨¡å‹è¾“å‡ºä¸Šæœ‰ä¸€äº›é‡è¦çš„å…ƒæ•°æ®ï¼Œé™¤äº†åŸå§‹æ–‡æœ¬ä¹‹å¤–ã€‚ä¸€ä¸ªä¾‹å­æ˜¯å·¥å…·è°ƒç”¨ï¼Œå…¶ä¸­æ‰“ç®—ä¼ é€’ç»™è¢«è°ƒç”¨å‡½æ•°çš„å‚æ•°åœ¨ä¸€ä¸ªå•ç‹¬çš„å±æ€§ä¸­è¿”å›ã€‚å¦‚æœæ‚¨éœ€è¦è¿™ç§æ›´ç»†ç²’åº¦çš„æ§åˆ¶ï¼Œæ‚¨å¯ä»¥æ”¹è€Œç»§æ‰¿`BaseGenerationOutputParser`ç±»ã€‚

è¿™ä¸ªç±»éœ€è¦ä¸€ä¸ªå•ä¸€çš„æ–¹æ³•`parse_result`ã€‚è¿™ä¸ªæ–¹æ³•æ¥å—åŸå§‹æ¨¡å‹è¾“å‡ºï¼ˆä¾‹å¦‚ï¼Œ`Generation`æˆ–`ChatGeneration`çš„åˆ—è¡¨ï¼‰å¹¶è¿”å›è§£æåçš„è¾“å‡ºã€‚

æ”¯æŒ`Generation`å’Œ`ChatGeneration`å…è®¸è§£æå™¨ä¸å¸¸è§„LLMä»¥åŠèŠå¤©æ¨¡å‹ä¸€èµ·å·¥ä½œã€‚

```python
from typing import List

from langchain_core.exceptions import OutputParserException
from langchain_core.messages import AIMessage
from langchain_core.output_parsers import BaseGenerationOutputParser
from langchain_core.outputs import ChatGeneration, Generation


class StrInvertCase(BaseGenerationOutputParser[str]):
    """An example parser that inverts the case of the characters in the message.

    This is an example parse shown just for demonstration purposes and to keep
    the example as simple as possible.
    """

    def parse_result(self, result: List[Generation], *, partial: bool = False) -> str:
        """Parse a list of model Generations into a specific format.

        Args:
            result: A list of Generations to be parsed. The Generations are assumed
                to be different candidate outputs for a single model input.
                Many parsers assume that only a single generation is passed it in.
                We will assert for that
            partial: Whether to allow partial results. This is used for parsers
                     that support streaming
        """
        if len(result) != 1:
            raise NotImplementedError(
                "This output parser can only be used with a single generation."
            )
        generation = result[0]
        if not isinstance(generation, ChatGeneration):
            # Say that this one only works with chat generations
            raise OutputParserException(
                "This output parser can only be used with a chat generation."
            )
        return generation.message.content.swapcase()


chain = anthropic | StrInvertCase()
```

è®©æˆ‘ä»¬æµ‹è¯•æ–°çš„è§£æå™¨ï¼å®ƒåº”è¯¥åè½¬æ¨¡å‹çš„è¾“å‡ºã€‚

```python
chain.invoke("Tell me a short sentence about yourself")
```