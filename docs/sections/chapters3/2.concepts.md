任何语言模型应用的核心元素是...模型的输入和输出。LangChain 为您提供了与任何语言模型进行接口交互的基本组件。

- `提示 prompts`: 将模型输入模板化、动态选择和管理
- `语言模型 models`: 通过常见接口调用语言模型
- `输出解析器 output_parsers`: 从模型输出中提取信息

![model I/O](https://python.langchain.com.cn/assets/images/model_io-e6fc0045b7eae0377a4ddeb90dc8cdb8.jpg)

## 1、models

LangChain集成了两种主要类型的模型：LLMs（大型语言模型）和聊天模型。这些模型根据它们的输入和输出类型来定义。

### （1）LLMs

在LangChain中，LLMs指的是纯文本完成模型。它们封装的API接受一个字符串提示作为输入，并输出一个字符串完成。OpenAI的GPT-3就是作为LLM实现的。

### （2）Chat Models

聊天模型通常由LLMs支持，但特别为进行对话而调整。重要的是，它们的提供者API使用与纯文本完成模型不同的接口。它们不是接受单个字符串，而是接受一系列聊天消息作为输入，并返回一个AI消息作为输出。GPT-4和Anthropic的Claude-2都是作为聊天模型实现的。

### （3）Messages

聊天模型接受一系列消息作为输入，并返回一个消息。有几种类型的消息。所有消息都有一个`role`（角色）和一个`content`（内容）属性。`role`描述了谁在说这个消息。LangChain为不同角色有不同的消息类。`content`属性描述了消息的内容。这可能是几种不同的东西：

- 一个字符串（大多数模型都是这样）
- 一个字典列表（这用于多模态输入，字典包含有关输入类型和输入位置的信息）

此外，消息有一个`additional_kwargs`属性。这是可以传递有关消息的额外信息的地方。这主要用于输入参数，这些参数是**提供者特定**的，而不是通用的。最好的例子是OpenAI的`function_call`。

### （4）HumanMessage

这代表来自用户的消息。通常只包含内容。

### （5）AIMessage

这代表来自模型的消息。这可能有`additional_kwargs` - 例如，如果使用OpenAI函数调用，则为`function_call`。

### （6）SystemMessage

这代表系统消息。只有一些模型支持这个。这告诉模型如何表现。这通常只包含内容。

### （7）FunctionMessage

这代表函数调用的结果。除了`role`和`content`之外，这个消息还有一个`name`参数，它传达了产生这个结果的函数的名称。

### （8）ToolMessage

这代表工具调用的结果。为了与OpenAI的`function`和`tool`消息类型匹配，这与函数消息有所不同。除了`role`和`content`之外，这个消息还有一个`tool_call_id`参数，它传达了被调用产生这个结果的工具调用的ID。

## 2、Prompts

语言模型的输入通常被称为提示。通常情况下，您应用程序中的用户输入并不是直接输入到模型的。相反，它们的输入以某种方式被转换，以产生最终进入模型的字符串或消息列表。将用户输入转换为最终字符串或消息的对象被称为“提示模板”。LangChain提供了几个抽象，以使处理提示更加容易。

### （1）PromptValue

聊天模型和LLMs接受不同的输入类型。提示值是一个旨在在两者之间互操作的类。它公开了一个方法，将其转换为字符串（与LLMs一起工作），另一个方法将其转换为消息列表（与聊天模型一起工作）。

### （2）PromptTemplate

这是一个提示模板的例子。这由一个模板字符串组成。然后，这个字符串与用户输入一起格式化，产生最终的字符串。

### （3）MessagePromptTemplate

这是一个提示模板的例子。这由一个具有特定角色和提示模板的消息组成。然后，这个提示模板与用户输入一起格式化，产生最终成为此消息`content`的字符串。

#### 1）HumanMessagePromptTemplate

这是产生人类消息的消息提示模板。

#### 2）AIMessagePromptTemplate

这是产生AI消息的消息提示模板。

#### 3）SystemMessagePromptTemplate

这是产生系统消息的消息提示模板。

### （4）MessagesPlaceholder

有时输入提示可以是一系列消息。这是您会使用消息占位符的时候。这些对象由`variable_name`参数参数化。具有与此`variable_name`值相同值的输入应该是一系列消息。

### （5）ChatPromptTemplate

这是一个提示模板的例子。这由一系列消息提示模板或消息占位符组成。然后，这些与用户输入一起格式化，产生最终的消息列表。

## 3、Output Parsers

模型的输出是字符串或消息。通常情况下，字符串或消息包含以特定格式格式化的信息，以便在下游使用（例如逗号分隔列表或JSON blob）。输出解析器负责接收模型的输出，并将其转换为更可用的形式。这些通常在输出消息的`content`上工作，但有时也会在`additional_kwargs`字段中的值上工作。

### （1）StrOutputParser

这是一个简单的输出解析器，它只是将语言模型（LLM或聊天模型）的输出转换为字符串。如果模型是LLM（因此输出一个字符串），它只是传递那个字符串。如果输出是聊天模型（因此输出一个消息），它通过消息的`.content`属性传递。

### （2）OpenAI Functions Parsers

有一些解析器专门用于处理OpenAI函数调用。它们接受`function_call`和`arguments`参数的输出（这些参数在`additional_kwargs`内部），并处理这些参数，基本上忽略内容。

### （3）Agent Output Parsers

代理是使用语言模型来确定采取哪些步骤的系统。因此，语言模型的输出需要被解析成一个可以表示将要采取的行动（如果有的话）的模式。代理输出解析器负责将原始LLM或聊天模型的输出转换为该模式。这些输出解析器内部的逻辑可以根据使用的模型和提示策略而有所不同。