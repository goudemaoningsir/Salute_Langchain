所有ChatModels实现了Runnable接口，该接口附带了所有方法的默认实现，即ainvoke、batch、abatch、stream、astream。这为所有ChatModels提供了基本的流式传输支持。

流式传输支持默认返回一个单个值的Iterator（或在异步流式传输的情况下是AsyncIterator），这是底层ChatModel提供者返回的最终结果。这显然不提供逐个token的流式传输，这需要ChatModel提供者的原生支持，但确保了期望token迭代器的代码可以适用于我们所有的ChatModel集成。

```python
from langchain_community.chat_models import ChatAnthropic
chat = ChatAnthropic(model="claude-2")
for chunk in chat.stream("Write me a song about goldfish on the moon"):
    print(chunk.content, end="", flush=True)
```

输出

```
这是一首我刚即兴创作的关于月球上的金鱼的歌曲：
在太空中漂浮，寻找一个地方
称之为家，孤独一人
穿过星星游泳，这些来自火星的金鱼
留下了鱼缸，寻找新生活
在月球上，那里的陨石坑隐约可见
寻找食物，也许是一些月球食物
超出了他们的深度，接近死亡
他们多么希望，只有一条小鱼
加入他们在这里，未来不明
在月球上，地球隐约可见
梦想着家，充满泡沫
他们的身体适应，持续存在
在月球上，他们学会陶醉
对着宇航员逗弄的奶酪
当他们凝视地球，出生的星球
这些离水的金鱼，继续游泳
月球的先驱，征服他们的恐惧
在月球上，他们快乐地陶醉
```

请注意，上述内容中的“流式传输”是指在处理数据流时，能够逐步接收和处理数据，而不是一次性接收所有数据。在LangChain中，ChatModels通过实现Runnable接口来支持流式传输，这意味着它们可以逐步生成和返回数据，而不是一次性返回所有结果。这对于处理大量数据或实时数据流非常有用，因为它允许程序在接收数据的同时进行处理，而不是等待所有数据到齐后再进行处理。