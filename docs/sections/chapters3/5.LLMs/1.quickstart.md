大型语言模型（LLMs）是LangChain的核心组成部分。LangChain不提供自己的LLMs，而是提供了一个标准接口，用于与许多不同的LLMs进行交互。

有许多LLM提供商（如OpenAI、Cohere、Hugging Face等）——`LLM`类旨在为所有这些提供商提供一个标准接口。

## 1、LLM模型LCEL

LLMs 实现 Runnable 接口，这是 LangChain 表达式语言（LCEL）的基本构建块。这意味着它们支持 `invoke` 、 `ainvoke` 、 `stream` 、 `astream` 、 `batch` 、 `abatch` , `astream_log` 调用。

LLMs 接受字符串作为输入，或可以强制为字符串提示的对象，包括 `List[BaseMessage]` 和 `PromptValue` 。

```python
from langchain_openai import OpenAI

print("####################      step1 初始化模型     ####################")
llm = OpenAI()
```

**invoke**

```python
print(llm.invoke(messages)) 
```
输出
```text
# 1. Phillips Curve Theory: This theory suggests an inverse relationship between unemployment and inflation. According to this theory, when unemployment is high, there is less demand for labor, leading to lower wages and prices. On the other hand, when unemployment is low, there is a higher demand for labor, resulting in higher wages and prices.

2. Expectations-Augmented Phillips Curve Theory: This theory builds upon the Phillips Curve theory by incorporating the impact of inflation expectations on the relationship between unemployment and inflation. It argues that if individuals have high expectations of future inflation, they will demand higher wages, which can lead to an increase in prices and inflation.

3. Rational Expectations Theory: This theory suggests that individuals make rational decisions based on all available information, including their expectations of future inflation. It argues that there is no long-term trade-off between unemployment and inflation as people will adjust their behavior and expectations accordingly.

4. Natural Rate of Unemployment Theory: This theory suggests that there is a "natural" rate of unemployment in the economy, which is determined by structural factors such as demographics, technology, and government policies. When unemployment falls below this level, inflationary pressures emerge, and when unemployment rises above this level, inflationary pressures decrease.

5. Cost-Push Inflation
```

**stream**

```python
for chunk in llm.stream(
    "What are some theories about the relationship between unemployment and inflation?"
):
    print(chunk, end="", flush=True)
```

**batch**

```python
llm.batch(
    [
        "What are some theories about the relationship between unemployment and inflation?"
    ]
)
```

**ainvoke**

```python
await llm.ainvoke(
    "What are some theories about the relationship between unemployment and inflation?"
)
```

**astream**

```python
async for chunk in llm.astream(
    "What are some theories about the relationship between unemployment and inflation?"
):
    print(chunk, end="", flush=True)
```

**astream_log**

```python
async for chunk in llm.astream_log(
    "What are some theories about the relationship between unemployment and inflation?"
):
    print(chunk)
```