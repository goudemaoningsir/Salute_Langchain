## 1、提示模板（Prompt Templates）

提示模板是为语言模型生成提示的预定义配方。模板可能包含指令、少数几个示例、以及适合特定任务的特定上下文和问题。

LangChain提供了创建和使用提示模板的工具。

LangChain致力于创建与模型无关的模板，以便于在不同的语言模型之间重用现有的模板。

通常，语言模型期望提示要么是一个字符串，要么是一个聊天消息列表。

## 2、`PromptTemplate`

使用`PromptTemplate`来创建一个字符串提示的模板。

默认情况下，`PromptTemplate`使用[Python的str.format](https://docs.python.org/3/library/stdtypes.html#str.format)语法进行模板化。

```python
from langchain.prompts import PromptTemplate
prompt_template = PromptTemplate.from_template("Tell me a {adjective} joke about {content}.")
prompt_template.format(adjective="funny", content="chickens")
```

模板支持任意数量的变量，包括没有变量：

```python
from langchain.prompts import PromptTemplate
prompt_template = PromptTemplate.from_template("Tell me a joke")
prompt_template.format()
```

你可以创建自定义的提示模板，以任何你想要的方式格式化提示。

## 3、`ChatPromptTemplate`

对于聊天模型的提示是一个聊天消息列表。

每个聊天消息都与内容相关联，并有一个额外的参数称为`role`。例如，在OpenAI的[聊天完成API](https://platform.openai.com/docs/guides/chat/introduction)中，一个聊天消息可以与AI助手、人类或系统角色相关联。

像这样创建一个聊天提示模板：

```python
from langchain_core.prompts import ChatPromptTemplate
chat_template = ChatPromptTemplate.from_messages([
    ("system", "You are a helpful AI bot. Your name is {name}."),
    ("human", "Hello, how are you doing?"),
    ("ai", "I'm doing well, thanks!"),
    ("human", "{user_input}"),
])
messages = chat_template.format_messages(name="Bob", user_input="What is your name?")
print(messages) # [SystemMessage(content='You are a helpful AI bot. Your name is Bob.'), HumanMessage(content='Hello, how are you doing?'), AIMessage(content="I'm doing well, thanks!"), HumanMessage(content='What is your name?')]
```

`ChatPromptTemplate.from_messages`接受多种消息表示形式。

例如，除了上面使用的(类型，内容)的2元组表示之外，你还可以传入`MessagePromptTemplate`或`BaseMessage`的实例。

```python
from langchain.prompts import HumanMessagePromptTemplate
from langchain_core.messages import SystemMessage

chat_template = ChatPromptTemplate.from_messages([
    SystemMessage(
        content=("You are a helpful assistant that re-writes the user's text to sound more upbeat."),
    ),
    HumanMessagePromptTemplate.from_template("{text}"),
])
messages = chat_template.format_messages(text="I don't like eating tasty things")
print(messages)
```

这为你在构建聊天提示时提供了很大的灵活性。

## 4、LCEL

`PromptTemplate`和`ChatPromptTemplate`实现了可运行接口，这是LangChain表达式语言（LCEL）的基本构建块。这意味着它们支持`invoke`、`ainvoke`、`stream`、`astream`、`batch`、`abatch`、`astream_log`调用。

`PromptTemplate`接受一个字典（提示变量）并返回一个`StringPromptValue`。

```python
from langchain.prompts import PromptTemplate
prompt_template = PromptTemplate.from_template("Tell me a {adjective} joke about {content}.")
prompt_val = prompt_template.invoke({"adjective": "funny", "content": "chickens"})
print(prompt_val) # text='Tell me a funny joke about chickens.'
```
`ChatPromptTemplate`接受一个字典并返回一个`ChatPromptValue`。

```python
from langchain.prompts import HumanMessagePromptTemplate
from langchain_core.messages import SystemMessage
from langchain_core.prompts import ChatPromptTemplate

chat_template = ChatPromptTemplate.from_messages([
    SystemMessage(
        content=("You are a helpful assistant that re-writes the user's text to sound more upbeat."),
    ),
    HumanMessagePromptTemplate.from_template("{text}"),
])
chat_val = chat_template.invoke({"text": "i dont like eating tasty things."})
print(chat_val) # messages=[SystemMessage(content="You are a helpful assistant that re-writes the user's text to sound more upbeat."), HumanMessage(content='i dont like eating tasty things.')]
```
