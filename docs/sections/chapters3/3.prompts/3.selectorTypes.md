## 1、示例选择器

LangChain 的示例选择器（Example Selector）是 LangChain 框架中的一个组件，用于从一组示例中选择最适合当前任务或问题的示例。LangChain 是一个用于构建和部署语言模型应用的开源工具库，它提供了一系列工具和组件，帮助开发者更容易地构建基于最新自然语言处理技术的应用。

示例选择器的主要目的是改善语言模型的表现，通过精选最相关的示例来提供给模型，以便模型能够更准确地理解当前的任务或问题，并生成更合适的回答。这在特定的应用场景下特别有用，比如需要模型在大量相似情况中做出最佳决策时。

基础接口定义如下：

```python
class BaseExampleSelector(ABC):
    """选择要包含在提示中的例子的接口。"""

    @abstractmethod
    def select_examples(self, input_variables: Dict[str, str]) -> List[dict]:
        """根据输入选择使用哪些例子。"""
        
    @abstractmethod
    def add_example(self, example: Dict[str, str]) -> Any:
        """Add new example to store."""
```

它唯一需要定义的方法是 `select_examples` 方法。此方法接受输入变量并返回一个示例列表。具体如何选择这些示例则取决于具体实现的策略。

为了使用示例选择器，我们首先需要创建一个示例列表，这通常应该是示例输入与输出。为了本示例，让我们假设我们正在选择如何进行中英翻译的示例。

```python
examples = [
    {"input": "hi", "output": "你好"},
    {"input": "bye", "output": "再见"},
    {"input": "soccer", "output": "足球"},
]
```

让我们编写一个根据单词长度选择例子的示例选择器。

```python
from langchain_core.example_selectors.base import BaseExampleSelector

class CustomExampleSelector(BaseExampleSelector):
    def __init__(self, examples):
        self.examples = examples

    def add_example(self, example):
        self.examples.append(example)

    def select_examples(self, input_variables):
        # 这假设输入的一部分将是 'text' 键
        new_word = input_variables["input"]
        new_word_length = len(new_word)

        # 初始化变量以存储最佳匹配及其长度差异
        best_match = None
        smallest_diff = float("inf")

        # 遍历每个例子
        for example in self.examples:
            # 计算例子的第一个单词与新单词的长度差异
            current_diff = abs(len(example["input"]) - new_word_length)

            # 如果当前差异更接近，则更新最佳匹配
            if current_diff < smallest_diff:
                smallest_diff = current_diff
                best_match = example

        return [best_match]
```

在 select_examples 方法中，它根据输入词的长度来选择最佳匹配的示例。具体逻辑是计算输入词与每个示例输入词长度的差异，然后选择差异最小的那个示例作为最佳匹配返回。

```python
example_selector = CustomExampleSelector(examples)

print(
    example_selector.select_examples({"input": "okay"})
)  # [{'input': 'bye', 'output': '再见'}]
```

```python
example_selector.add_example({"input": "hand", "output": "手"})

selected_example = example_selector.select_examples({"input": "hand"})
print(selected_example)  # 预期输出：[{'input': 'hand', 'output': '手'}]
```

我们现在可以在提示中使用这个示例选择器

```python
from langchain_core.prompts.few_shot import FewShotPromptTemplate
from langchain_core.prompts.prompt import PromptTemplate

example_prompt = PromptTemplate.from_template("Input: {input} -> Output: {output}")

prompt = FewShotPromptTemplate(
    example_selector=example_selector,
    example_prompt=example_prompt,
    suffix="Input: {input} -> Output:",
    prefix="Translate the following words from English to chinese:",
    input_variables=["input"],
)

print(prompt.format(input="word"))

# Translate the following words from English to chinese:
# Input: 手 -> Output: hand
# Input: 词 -> Output:
```

通过这种方式，示例选择器不仅使我们能够基于具体需求选择合适的示例来优化提示，还提高了语言模型处理特定翻译任务时的效率和准确性。

## 2、基于长度的示例选择器

这个机制通过考虑示例的长度来决定在构建提示时包含哪些示例。它尤其适用于需要控制提示长度以适应模型上下文窗口限制的情况。简单来说，对于较长的输入，它会选择较少数量的示例以减少总长度；对于较短的输入，则可能包含更多示例。

```python
from langchain.prompts import FewShotPromptTemplate, PromptTemplate
from langchain.prompts.example_selector import LengthBasedExampleSelector
# 假设任务是创建反义词的示例。
examples = [
    {"input": "happy", "output": "sad"},
    {"input": "tall", "output": "short"},
    {"input": "energetic", "output": "lethargic"},
    {"input": "sunny", "output": "gloomy"},
    {"input": "windy", "output": "calm"},
]
example_prompt = PromptTemplate(
    input_variables=["input", "output"],
    template="Input: {input}\nOutput: {output}",
)
example_selector = LengthBasedExampleSelector(
    # 可供选择的示例。
    examples=examples,
    # 用于格式化示例的PromptTemplate。
    example_prompt=example_prompt,
    # 格式化后的示例的最大长度。
    # 长度是通过下面的get_text_length函数来衡量的。
    max_length=25,
    # 用于获取字符串长度的函数，
    # 用于确定包含哪些示例。如果没有指定，则会使用默认值。
    # get_text_length: Callable[[str], int] = lambda x: len(re.split("\n| ", x))
)
dynamic_prompt = FewShotPromptTemplate(
    # 我们提供了一个ExampleSelector而不是示例。
    example_selector=example_selector,
    example_prompt=example_prompt,
    prefix="Give the antonym of every input",
    suffix="Input: {adjective}\nOutput:",
    input_variables=["adjective"],
)
```

### （1）实现步骤

**定义示例**：首先，准备一个示例列表，每个示例由“输入”和对应的“输出”组成。这些示例用于教导模型完成特定的任务，例如生成反义词。

```python
examples = [
    {"input": "happy", "output": "sad"},
    {"input": "tall", "output": "short"},
    # 更多示例...
]
```

**示例格式化**：使用`PromptTemplate`定义如何格式化单个示例，指定输入和输出的显示方式。

```python
example_prompt = PromptTemplate(
    input_variables=["input", "output"],
    template="Input: {input}\nOutput: {output}",
)
```

**长度基选择器**：通过`LengthBasedExampleSelector`根据示例的总长度来选择示例。这里，您可以指定示例的最大长度，选择器将尝试在不超过此长度的前提下包含尽可能多的示例。

```python
example_selector = LengthBasedExampleSelector(
    examples=examples,
    example_prompt=example_prompt,
    max_length=25,
)
```

**动态提示构建**：使用`FewShotPromptTemplate`结合前面的选择器和格式化模板来构建动态的提示。这种提示会根据输入的长度动态调整包含的示例数量。

```python
dynamic_prompt = FewShotPromptTemplate(
    example_selector=example_selector,
    example_prompt=example_prompt,
    prefix="Give the antonym of every input",
    input_variables=["adjective"],
)
```

### （2）使用示例

**短输入**：对于简短的输入，选择器会包含更多示例，因为总长度允许。

```python
print(dynamic_prompt.format(adjective="big"))
```

```text
Give the antonym of every input
Input: happy
Output: sad
Input: tall
Output: short
Input: energetic
Output: lethargic
Input: sunny
Output: gloomy
Input: windy
Output: calm
Input: big
Output:
```

**长输入**：当输入较长，接近或超过设定的最大长度限制时，选择器会减少包含的示例数量，以确保总长度不会超标。

```python
long_string = "big and huge and massive and large and gigantic and tall and much much much much much bigger than everything else"
print(dynamic_prompt.format(adjective=long_string))
```
```text
Give the antonym of every input
Input: happy
Output: sad
Input: big and huge and massive and large and gigantic and tall and much much much much much bigger than everything else
Output:
```

**添加新示例**：您还可以动态地向选择器中添加新的示例，并立即在提示构建中使用它。

```python
new_example = {"input": "big", "output": "small"}
dynamic_prompt.example_selector.add_example(new_example)
print(dynamic_prompt.format(adjective="enthusiastic"))
```
```text
Give the antonym of every input
Input: happy
Output: sad
Input: tall
Output: short
Input: energetic
Output: lethargic
Input: sunny
Output: gloomy
Input: windy
Output: calm
Input: big
Output: small
Input: enthusiastic
Output:
```

通过这种方式，基于长度的示例选择器为构建动态且灵活的提示提供了一种高效的方法，使其既能适应模型的限制，又能根据输入的具体情况灵活调整示例的数量。

## 3、基于最大边际相关性（MMR）选择

在 LangChain 库中，基于最大边际相关性（Maximum Marginal Relevance, MMR）的选择器是一个高级的示例选择方法，它旨在平衡相关性（与查询条件的匹配度）和多样性（选定示例间的差异），以选出最适合当前任务的示例集。MMR 最初被设计用于信息检索和文档摘要场景，用以提取既相关又多样化的信息，从而避免重复并提高信息的覆盖率。

### （1）MMR 的工作原理

MMR 通过一个可调节的参数λ来平衡相关性和多样性，λ的值在0到1之间。λ值越大，选择过程越偏重于相关性；λ值越小，则越偏重于多样性。
$$
MMR = λ · 相关性(文档, 查询) - (1 - λ) · max(相似性(文档, d'))
$$
其中：

- `λ` 是一个介于 0 到 1 之间的参数，用于平衡相关性和多样性的重要性。
- `相关性(文档, 查询)` 表示文档和查询之间的相关度。
- `相似性(文档, d')` 表示当前考虑的文档与已选文档集合中任一文档 `d'` 之间的相似度。
- `max(相似性(文档, d'))` 表示当前文档与已选文档集合中最相似文档的相似度。

### （2）在 LangChain 中的应用

在 LangChain 的上下文中，MMR 选择器可以应用于选择示例、生成文本摘要或任何需要从大量文本中挑选出既相关又具有多样性文本的场景。特别是在构建提示（prompt）时，使用 MMR 选择器可以帮助确保选出的示例既能覆盖用户查询的核心内容，又能防止示例之间的重复，从而提高语言模型的效果。

例如，如果你正在构建一个聊天机器人，需要根据用户的问题从一个大型FAQ数据库中选出几个最相关的问题和答案作为模型的输入提示，使用MMR选择器就可以确保这些问题既相关（即与用户问题紧密相关）又多样（即相互之间不太相似），避免了选出多个高度相似的问题，从而提高了回答的质量和覆盖范围。

```python
from langchain.prompts import FewShotPromptTemplate, PromptTemplate
from langchain.prompts.example_selector import (
    MaxMarginalRelevanceExampleSelector,
    SemanticSimilarityExampleSelector,
)
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings

example_prompt = PromptTemplate(
    input_variables=["input", "output"],
    template="Input: {input}\nOutput: {output}",
)

# 假设任务是创建反义词的示例。
examples = [
    {"input": "happy", "output": "sad"},
    {"input": "tall", "output": "short"},
    {"input": "energetic", "output": "lethargic"},
    {"input": "sunny", "output": "gloomy"},
    {"input": "windy", "output": "calm"},
]
```

```python
example_selector = MaxMarginalRelevanceExampleSelector.from_examples(
    # 可供选择的示例列表。
    examples,
    # 用于生成嵌入（用于测量语义相似度）的嵌入类。
    OpenAIEmbeddings(),
    # 用于存储嵌入并进行相似性搜索的VectorStore类。
    FAISS,
    # 要生成的示例数量。
    k=2,
)
mmr_prompt = FewShotPromptTemplate(
    # 我们提供了一个ExampleSelector而不是示例。
    example_selector=example_selector,
    example_prompt=example_prompt,
    prefix="Give the antonym of every input",
    suffix="Input: {adjective}\nOutput:",
    input_variables=["adjective"],
)
```

```python
# 输入是一种感觉，所以应该选择happy/sad示例作为第一个。
print(mmr_prompt.format(adjective="worried"))
```

```python
Give the antonym of every input
Input: happy
Output: sad
Input: windy
Output: calm
Input: worried
Output:
```

```python
# 让我们比较一下，如果我们只根据相似度选择，使用SemanticSimilarityExampleSelector代替MaxMarginalRelevanceExampleSelector会得到什么。
example_selector = SemanticSimilarityExampleSelector.from_examples(
    # 可供选择的示例列表。
    examples,
    # 用于生成嵌入（用于测量语义相似度）的嵌入类。
    OpenAIEmbeddings(),
    # 用于存储嵌入并进行相似性搜索的VectorStore类。
    FAISS,
    # 要生成的示例数量。
    k=2,
)
similar_prompt = FewShotPromptTemplate(
    # 我们提供了一个ExampleSelector而不是示例。
    example_selector=example_selector,
    example_prompt=example_prompt,
    prefix="Give the antonym of every input",
    suffix="Input: {adjective}\nOutput:",
    input_variables=["adjective"],
)
print(similar_prompt.format(adjective="worried"))
```

```python
Give the antonym of every input
Input: happy
Output: sad
Input: sunny
Output: gloomy
Input: worried
Output:
```

## 4、基于n-gram重叠选择

基于 n-gram 重叠的选择方法是一种测量和选择文本示例的技术，它侧重于评估文本之间在 n-gram 层面上的相似性或重叠程度。n-gram 是文本中连续的 n 个项目（例如单词、字符）的序列，这种方法通过计算这些序列的匹配程度来评估文本之间的相似性。

### （1）N-gram 的概念

n-gram 模型是一种语言模型，用于预测序列中的下一个项目（如单词或字母）。在这个上下文中，"n" 表示序列中的项目数。例如，一个 "unigram" (1-gram) 涉及单个项目的序列，"bigram" (2-gram) 涉及两个项目的序列，以此类推。通过分析文本中 n-gram 的分布，可以捕获到其语言学特征，如语法结构和词汇使用模式。

### （2）基于n-gram重叠选择

`NGramOverlapExampleSelector`根据示例与输入的相似性来选择和排序示例，这是根据n-gram重叠得分来衡量的。n-gram重叠得分是一个介于0.0和1.0之间的浮点数（包括0.0和1.0）。

选择器允许设置一个阈值得分。n-gram重叠得分小于或等于阈值的示例将被排除。默认情况下，阈值设置为-1.0，所以不会排除任何示例，只会重新排序它们。将阈值设置为0.0将排除与输入没有n-gram重叠的示例。

```python
from langchain.prompts import FewShotPromptTemplate, PromptTemplate
from langchain.prompts.example_selector.ngram_overlap import NGramOverlapExampleSelector
example_prompt = PromptTemplate(
    input_variables=["input", "output"],
    template="Input: {input}\nOutput: {output}",
)

# 一个虚构的翻译任务的示例。
examples = [
    {"input": "See Spot run.", "output": "Ver correr a Spot."},
    {"input": "My dog barks.", "output": "Mi perro ladra."},
    {"input": "Spot can run.", "output": "Spot puede correr."},
]
```

```python
example_selector = NGramOverlapExampleSelector(
    # 可供选择的示例。
    examples=examples,
    # 用于格式化示例的PromptTemplate。
    example_prompt=example_prompt,
    # 选择器停止的阈值。
    # 默认设置为-1.0。
    threshold=-1.0,
    # 对于负阈值：
    # 选择器按n-gram重叠得分排序示例，并不排除任何示例。
    # 对于大于1.0的阈值：
    # 选择器排除所有示例，并返回空列表。
    # 对于等于0.0的阈值：
    # 选择器按n-gram重叠得分排序示例，
    # 并排除与输入没有n-gram重叠的示例。
)
dynamic_prompt = FewShotPromptTemplate(
    # 我们提供了一个ExampleSelector而不是示例。
    example_selector=example_selector,
    example_prompt=example_prompt,
    prefix="Give the Spanish translation of every input",
    suffix="Input: {sentence}\nOutput:",
    input_variables=["sentence"],
)
```
一个与“Spot can run.”有大量n-gram重叠，与“My dog barks.”没有重叠的示例输入。
```python
print(dynamic_prompt.format(sentence="Spot can run fast."))
```
输出
```python
Give the Spanish translation of every input
Input: Spot can run
Output: Spot puede correr
Input: See Spot run
Output: Ver correr a Spot
Input: My dog barks
Output: Mi perro ladra
Input: Spot can run fast
Output:
```

```python
# 你也可以向NGramOverlapExampleSelector添加示例。
new_example = {"input": "Spot plays fetch.", "output": "Spot juega a buscar."}
example_selector.add_example(new_example)
print(dynamic_prompt.format(sentence="Spot can run fast."))
```

```python
Give the Spanish translation of every input
Input: Spot can run
Output: Spot puede correr
Input: See Spot run
Output: Ver correr a Spot
Input: Spot plays fetch
Output: Spot juega a buscar
Input: My dog barks
Output: Mi perro ladra
Input: Spot can run fast
Output:
```
你可以设置一个阈值，超过该阈值的示例将被排除。例如，将阈值设置为0.0将排除与输入没有n-gram重叠的示例。由于“My dog barks.”与“Spot can run fast.”没有n-gram重叠，它被排除了。
```python
example_selector.threshold = 0.0
print(dynamic_prompt.format(sentence="Spot can run fast."))
```
输出
```python
Give the Spanish translation of every input
Input: Spot can run
Output: Spot puede correr
Input: See Spot run
Output: Ver correr a Spot
Input: Spot plays fetch
Output: Spot juega a buscar
Input: Spot can run fast
Output:
```
设置一个小的非零阈值
```python
example_selector.threshold = 0.09
print(dynamic_prompt.format(sentence="Spot can play fetch."))
```
输出
```python
Give the Spanish translation of every input
Input: Spot can run
Output: Spot puede correr
Input: Spot plays fetch
Output: Spot juega a buscar
Input: Spot can play fetch
Output:
```
设置大于1.0的阈值
```python
example_selector.threshold = 1.0 + 1e-9
print(dynamic_prompt.format(sentence="Spot can play fetch."))
```
输出
```python
Give the Spanish translation of every input
Input: Spot can play fetch
Output:
```

## 5、基于相似性选择

这个对象根据与输入的相似性来选择示例。它通过寻找嵌入（embeddings）与输入具有最大余弦相似度的示例来实现这一点。

```python
from langchain.prompts import FewShotPromptTemplate, PromptTemplate
from langchain.prompts.example_selector import SemanticSimilarityExampleSelector
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings

example_prompt = PromptTemplate(
    input_variables=["input", "output"],
    template="Input: {input}\nOutput: {output}",
)

# 假设任务是创建反义词的示例。
examples = [
    {"input": "happy", "output": "sad"},
    {"input": "tall", "output": "short"},
    {"input": "energetic", "output": "lethargic"},
    {"input": "sunny", "output": "gloomy"},
    {"input": "windy", "output": "calm"},
]
```

```python
example_selector = SemanticSimilarityExampleSelector.from_examples(
    # 可供选择的示例列表。
    examples,
    # 用于生成嵌入（用于测量语义相似度）的嵌入类。
    OpenAIEmbeddings(),
    # 用于存储嵌入并进行相似性搜索的VectorStore类。
    Chroma,
    # 要生成的示例数量。
    k=1,
)
similar_prompt = FewShotPromptTemplate(
    # 我们提供了一个ExampleSelector而不是示例。
    example_selector=example_selector,
    example_prompt=example_prompt,
    prefix="Give the antonym of every input",
    suffix="Input: {adjective}\nOutput:",
    input_variables=["adjective"],
)
```
输入是一种感觉，所以应该选择happy/sad示例。
```python
print(similar_prompt.format(adjective="worried"))
```
输出
```python
Give the antonym of every input
Input: happy
Output: sad
Input: worried
Output:
```
输入是一个度量，所以应该选择tall/short示例。
```python
print(similar_prompt.format(adjective="large"))
```
输出
```python
Give the antonym of every input
Input: tall
Output: short
Input: large
Output:
```
你也可以向SemanticSimilarityExampleSelector添加新的示例。
```python
similar_prompt.example_selector.add_example(
    {"input": "enthusiastic", "output": "apathetic"}
)
print(similar_prompt.format(adjective="passionate"))
```
输出
```python
Give the antonym of every input
Input: enthusiastic
Output: apathetic
Input: passionate
Output:
```

## 6、MaxMarginalRelevanceExampleSelector和SemanticSimilarityExampleSelector的区别

`MaxMarginalRelevanceExampleSelector`（最大边际相关性选择器）和`SemanticSimilarityExampleSelector`（语义相似性选择器）都是在自然语言处理（NLP）和机器学习领域用于选择文本示例的方法。尽管它们的目标相似，即从一组候选中选择最合适的示例，但它们在实现这一目标的方法和侧重点上存在显著差异。

### （1）MaxMarginalRelevanceExampleSelector（最大边际相关性选择器）

`MaxMarginalRelevanceExampleSelector` 旨在通过平衡「相关性」和「多样性」来选择示例。它使用最大边际相关性（MMR）算法来解决当候选文本集合中的文本高度相关时可能出现的冗余问题。MMR 通过一个可调节的参数λ来平衡这两者，从而在相关性（即与查询内容的匹配程度）和多样性（选定示例间的差异性）之间做出权衡。

- **应用场景：** MMR 特别适合于需要综合考虑文本相关性和提供信息多样性的场景，如生成文档摘要或构建信息检索系统。

### （2）SemanticSimilarityExampleSelector（语义相似性选择器）

`SemanticSimilarityExampleSelector` 侧重于评估和选择在语义层面上与给定查询或文本最相似的示例。它通常依赖于预训练的语言模型（如BERT、GPT）来理解文本的深层语义内容，并通过计算语义向量之间的相似度（例如，使用余弦相似度）来选择最相关的示例。

- **应用场景：** 这种选择器适用于强调深层语义理解和匹配的应用场景，如问答系统、个性化推荐或内容匹配。

### （3）主要区别

- **侧重点不同：** MMR 强调在相关性和多样性之间找到最佳平衡点，而语义相似性选择器专注于找出在深层语义上最接近给定查询或文本的示例。
- **算法实现：** MMR 使用一种算法框架，在选择过程中动态考虑已选择示例的集合，以减少冗余。相比之下，语义相似性选择器更多地依赖于语言模型的能力来理解和比较文本的语义内容。
- **应用场景：** MMR 更适合那些需要同时考虑提供综合信息（相关性和多样性）的场景，而语义相似性选择器更适用于那些需要深入理解文本语义以找到最匹配示例的场景。

总的来说，选择哪种方法取决于特定的应用需求、文本数据的特性以及期望解决的问题。在实际应用中，这两种方法也可以结合使用，以充分利用它们各自的优势。
